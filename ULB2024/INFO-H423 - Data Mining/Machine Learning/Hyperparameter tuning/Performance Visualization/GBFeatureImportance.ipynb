{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d35e8e0-8ed3-43df-99ff-d074ccbce734",
   "metadata": {},
   "source": [
    "**GRADIENT BOOSTING (GB)**\n",
    "\n",
    "**DATA LOADING AND PREPARATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d1dece-7ab4-460f-b147-96d4e170b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e621fda5-0943-4a16-bf4b-ef943cf6de6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1011 entries, 0 to 1010\n",
      "Columns: 828 entries, incident_id to 998\n",
      "dtypes: float64(826), int64(1), string(1)\n",
      "memory usage: 6.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV\n",
    "tfidf_df = pd.read_csv(\"tfidf_sncb.csv\", sep='\\,', engine='python')\n",
    "\n",
    "tfidf_df['incident_type'] = tfidf_df['incident_type'].astype('string') \n",
    "\n",
    "tfidf_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db029af2-2198-4aa1-b5a4-65741c9d6515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train_val_X pandas df has 808 rows and 826 columns.\n",
      "The test_y pandas series has 203 rows and 1 column.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Filter in the Features (the values acquired from the events sequence after TF-IDF)\n",
    "X = tfidf_df.drop(['incident_type', 'incident_id'], axis=1) \n",
    "\n",
    "# Filter in the Target variable (labels / incident types)\n",
    "y = tfidf_df['incident_type']  \n",
    "\n",
    "# setting random_state constant to be used in the whole pipeline and guarantee reproducibility\n",
    "r_state = 123\n",
    "\n",
    "# Split data into training+validation and testing sets\n",
    "train_val_X, test_X, train_val_y, test_y = train_test_split(X, \n",
    "                                                            y, \n",
    "                                                            train_size = 0.8, \n",
    "                                                            random_state = r_state, # setting random_state for reproducibility\n",
    "                                                            stratify = y) # to respect class imbalance in the label column\n",
    "\n",
    "print(f\"The train_val_X pandas df has {len(train_val_X)} rows and {len(train_val_X.columns)} columns.\")\n",
    "print(f\"The test_y pandas series has {len(test_y)} rows and 1 column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6553064-17ab-4507-841d-28d033d59e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In RepeatedStratifiedKFold() function, the parameter n_splits has to be set atmost to 3, due to class imbalance in the label column.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# get the size of the smallest incident type class\n",
    "value_counts = Counter(train_val_y)\n",
    "min_class_setsize = min(value_counts.values())\n",
    "\n",
    "print(f\"In RepeatedStratifiedKFold() function, the parameter n_splits has to be set atmost to {min_class_setsize}, due to class imbalance in the label column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e614cef-29b3-4885-972f-39df03a4c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Define the base model\n",
    "model_gb = GradientBoostingClassifier(random_state = r_state,\n",
    "                                      loss = \"log_loss\", # exponential works only for binary classification\n",
    "                                      criterion = \"friedman_mse\", # tested [\"squared_error\"]\n",
    "                                      max_features = 0.12 # tested [100, 0.15, 0.20]\n",
    "                                     )\n",
    "\n",
    "# Set up cross-validation\n",
    "rskf = RepeatedStratifiedKFold(n_splits = min_class_setsize, \n",
    "                               n_repeats = 34, \n",
    "                               random_state = r_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71c940-735d-4b1f-b59c-ad73e542bbbb",
   "metadata": {},
   "source": [
    "**MODEL TRAINING AND VALIDATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5e359-c588-4e1c-b000-be8d5d801725",
   "metadata": {},
   "source": [
    "**TEST SET RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ff95d7d-a527-409a-9dc5-55a29e14d1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Predict on the test set\\ntest_pred_y = model_gb.predict(test_X)\\n\\n# Compute and display metrics\\nprint(f\"The model classified correctly {sum(test_y == test_pred_y)} entries from a total of {len(test_X)}.\\n\")\\n\\nprint(f\"Accuracy on test set:          {accuracy_score(test_y, test_pred_y)}\")\\nprint(f\"Weighted F1-Score on test set: {f1_score(test_y, test_pred_y, average=\\'weighted\\')}\\n\")\\n\\nprint(\"F1-Score per class\\n\")\\n\\n# Generate classification report\\nreport = classification_report(test_y, test_pred_y, output_dict=True, zero_division=0)\\n\\n# Display F1-score per class\\nfor class_label, metrics in report.items():\\n    if isinstance(metrics, dict) and \\'f1-score\\' in metrics:\\n        print(f\"Class {class_label}: F1-Score = {metrics[\\'f1-score\\']:.6f}\")\\n\\nprint(\"\\nAccuracy per class\\n\")\\n\\n# Display F1-score per class\\nfor class_label, metrics in report.items():\\n    if isinstance(metrics, dict) and \\'recall\\' in metrics:\\n        print(f\"Class {class_label}: Recall = {metrics[\\'recall\\']:.6f}\") # Recall is equivalent to per-class accuracy\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Train the base model\n",
    "model_gb.fit(X, y)\n",
    "\n",
    "\"\"\"\n",
    "# Predict on the test set\n",
    "test_pred_y = model_gb.predict(test_X)\n",
    "\n",
    "# Compute and display metrics\n",
    "print(f\"The model classified correctly {sum(test_y == test_pred_y)} entries from a total of {len(test_X)}.\\n\")\n",
    "\n",
    "print(f\"Accuracy on test set:          {accuracy_score(test_y, test_pred_y)}\")\n",
    "print(f\"Weighted F1-Score on test set: {f1_score(test_y, test_pred_y, average='weighted')}\\n\")\n",
    "\n",
    "print(\"F1-Score per class\\n\")\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(test_y, test_pred_y, output_dict=True, zero_division=0)\n",
    "\n",
    "# Display F1-score per class\n",
    "for class_label, metrics in report.items():\n",
    "    if isinstance(metrics, dict) and 'f1-score' in metrics:\n",
    "        print(f\"Class {class_label}: F1-Score = {metrics['f1-score']:.6f}\")\n",
    "\n",
    "print(\"\\nAccuracy per class\\n\")\n",
    "\n",
    "# Display F1-score per class\n",
    "for class_label, metrics in report.items():\n",
    "    if isinstance(metrics, dict) and 'recall' in metrics:\n",
    "        print(f\"Class {class_label}: Recall = {metrics['recall']:.6f}\") # Recall is equivalent to per-class accuracy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d61058-0279-4d18-8485-a1ca30d91335",
   "metadata": {},
   "source": [
    "**SAVE AND EXPORT RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "425606f0-b53e-463a-9c24-8b1d4d98ad80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0.043043</td>\n",
       "      <td>4080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0.027375</td>\n",
       "      <td>3548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.022573</td>\n",
       "      <td>3528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.022431</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.021125</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>826 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     importance feature\n",
       "652    0.043043    4080\n",
       "534    0.027375    3548\n",
       "527    0.022573    3528\n",
       "811    0.022431     942\n",
       "276    0.021125    2492\n",
       "..          ...     ...\n",
       "807    0.000000     920\n",
       "806    0.000000     906\n",
       "771    0.000000      66\n",
       "775    0.000000     678\n",
       "330    0.000000    2670\n",
       "\n",
       "[826 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_importance_df = pd.DataFrame({'importance': model_gb.feature_importances_,\n",
    "                                 'feature': model_gb.feature_names_in_\n",
    "                                })\n",
    "\n",
    "gb_importance_df.sort_values('importance', ascending=False, inplace=True)\n",
    "\n",
    "gb_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5f33ec4-8ea1-4018-89c2-b21dafd660c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame of Feature Importance\n",
    "gb_importance_df.to_csv('gb_importance.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
